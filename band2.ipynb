{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import affine_transform\n",
    "\n",
    "import random\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = listdir(\"dataWeb\")\n",
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    d = pd.read_pickle(\"dataWeb/\"+f)\n",
    "    #data = data.append(d)\n",
    "    data = pd.concat([data,d], ignore_index=True)\n",
    "data.columns = [\"band\",\"style\",\"img\",\"shape\",\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveJunk(d):\n",
    "    BlackPic,WhitePic = np.zeros((200,200,3)), np.ones((200,200,3))\n",
    "    d = d.drop_duplicates(subset=\"band\") #remove duplicates\n",
    "    d = d[(d[\"shape\"]==(200, 200, 3))] #only consistent image matrix shapes (3D)\n",
    "    #d = d[(d[\"img\"]!=BlackPic)]\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = RemoveJunk(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"img\"].loc[54], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"style\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StyleDictionnary ={\"Doom\": \"Doom Metal\",\n",
    "                   \"Drone\":\"Doom Metal\",\n",
    "                   \"Sludge\":\"Doom Metal\",\n",
    "                   \"Sludge Metal\":\"Doom Metal\",\n",
    "                   \"Death\":\"Death Metal\",\n",
    "                   \"Folk\":\"Folk Metal\",\n",
    "                   \"Power\":\"Power Metal\",\n",
    "                   \"Heavy\":\"Heavy Metal\",\n",
    "                   \"Pagan\":\"Folk Metal\",\n",
    "                   \"Viking\":\"Folk Metal\",\n",
    "                   \"Neoclassical\": \"Symphonic\",\n",
    "                   \"Progressive\":\"Progressive Metal\",\n",
    "                   \"Deathcore\":\"Metalcore\",\n",
    "                   \"Grindcore\":\"Metalcore\",\n",
    "                   \"Hardcore\":\"Metalcore\",\n",
    "                   \"Thrash\":\"Thrash Metal\",\n",
    "                   \"Brutal Death Metal\":\"Death Metal\",\n",
    "                   \"Technical Death\":\"Death Metal\",\n",
    "                   \"Gothic\": \"Gothic Metal\",\n",
    "                   \"Black\":\"Black Metal\"}\n",
    "\n",
    "CommonAdjectives = [\"Atmospheric\",\"Melodic\",\"Blackened\",\"Experimental\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggregateStyle(s, dic):\n",
    "    if s in dic: \n",
    "        return(dic[s])\n",
    "    else: \n",
    "        return(s)\n",
    "\n",
    "def AggregateStyle2(s,adj):\n",
    "    sl = s.split(' ',1)\n",
    "    if len(sl)>1: \n",
    "        if sl[0] in adj: \n",
    "            return(sl[1])\n",
    "        if sl[0] == \"Progressive\":        # not sure about this one (we'll see)\n",
    "            return(\"Progressive Metal\")\n",
    "    else:\n",
    "        return(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"style\"] = data[\"style\"].apply(AggregateStyle2, args=(CommonAdjectives,))\n",
    "data[\"style\"] = data[\"style\"].map(lambda a: AggregateStyle(a,StyleDictionnary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"style\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too mutch death, let's remove some (say 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toRemove = data.loc[data[\"style\"]==\"Death Metal\"].sample(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(toRemove.index, axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"style\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"minor\" categories \n",
    "BigOnes = data[\"style\"].value_counts()[:13]\n",
    "data = data[(data[\"style\"].isin(BigOnes.index))]\n",
    "data[\"style\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in a separate pickle \n",
    "data = data.reset_index(drop=True)\n",
    "#data.to_pickle(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data\")\n",
    "data = data.reset_index(drop=True)\n",
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"imgR\"] = data[\"img\"].map(lambda a: np.flip(a,1)) # reverse image along L (axis 1)\n",
    "data[\"imgRed\"] = data[\"img\"].map(lambda a :np.power(a,[1.5, 1.0, 1.0])) # reduce red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/40060786/scipy-ndimage-interpolate-affine-transform-fails\n",
    "\n",
    "def makeReal(im): # affine transformation \"flip\" pics slightly\n",
    "    ang1, ang2 = random.uniform(0.9,1.1),random.uniform(-0.2,0.2)\n",
    "\n",
    "    matrix = [[ ang1, ang2,  0.0],\n",
    "              [ ang2, ang1,  0],\n",
    "              [   0,   0,  1]]\n",
    "\n",
    "    return(affine_transform(im, matrix, order=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"imgReal\"] = data[\"img\"].map(lambda a :makeReal(a)) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"img\"].loc[50], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"imgR\"].loc[50], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"imgRed\"].loc[50], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[\"imgReal\"].loc[50], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN at last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(np.random.permutation(data.index)) # shuffle data\n",
    "\n",
    "#X = np.concatenate([np.expand_dims(data[\"img\"][i], axis=0) for i in  range(len(data[\"img\"]))],axis=0) #images\n",
    "#Y = pd.get_dummies(data[\"style\"], columns=[\"style\"]).values # labels\n",
    "\n",
    "X1 = np.concatenate([np.expand_dims(data[\"img\"][i], axis=0) for i in  range(len(data[\"img\"]))],axis=0) #images\n",
    "X2 = np.concatenate([np.expand_dims(data[\"imgR\"][i], axis=0) for i in  range(len(data[\"imgR\"]))],axis=0) #images\n",
    "X3 = np.concatenate([np.expand_dims(data[\"imgRed\"][i], axis=0) for i in  range(len(data[\"imgRed\"]))],axis=0)#images\n",
    "X4 = np.concatenate([np.expand_dims(data[\"imgReal\"][i], axis=0) for i in  range(len(data[\"imgReal\"]))],axis=0)\n",
    "X = np.concatenate([X1,X2,X3,X4], axis =0)\n",
    "\n",
    "dummies = pd.get_dummies(data[\"style\"], columns=[\"style\"])\n",
    "\n",
    "Y = pd.get_dummies(data[\"style\"], columns=[\"style\"]).values # labels\n",
    "Y = np.concatenate([Y,Y,Y,Y], axis =0)\n",
    "\n",
    "X_train,X_test  = X[200:],X[:200]\n",
    "Y_train,Y_test  = Y[200:],Y[:200]\n",
    "\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X1,X2,X3,X4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetalModel(input_shape):\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    X_input = Input(input_shape)\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((7, 7))(X_input)\n",
    "    \n",
    "    # 2D CONV\n",
    "    X = Conv2D(32, (3, 3), strides = (2, 2), name = 'conv0')(X)\n",
    "    #X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "    \n",
    "    # 2D CONV\n",
    "    X = ZeroPadding2D((7, 7))(X)\n",
    "    X = Conv2D(64, (7, 7), strides = (1, 1), name = 'conv1')(X)\n",
    "    #X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X= Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    \n",
    "    \n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(13, activation='softmax', name='fc',bias_initializer='zeros')(X)\n",
    "    # Create model. \n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    ### END CODE HERE ###\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalModel = MetalModel((200,200,3))\n",
    "metalModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalModel.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", metrics = [\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalModel.fit(x = X_train, y = Y_train, epochs = 10,verbose=1, batch_size = 64,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metalModel.evaluate(X_test, Y_test, verbose=0)\n",
    "score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metalModel.save(\"metal-model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
